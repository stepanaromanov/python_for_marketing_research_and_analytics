{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6b910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('User churn.csv')\n",
    "data.columns = data.columns.str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9f85c",
   "metadata": {},
   "source": [
    "<b>Encoding binary features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "mapping = {'Yes': 1, 'No': 0}\n",
    "# Binary features\n",
    "binary = []\n",
    "# Apply the mapping to each column where we have only 'Yes' and 'No' values\n",
    "for col in data.columns:\n",
    "    if set(data[col].unique()).issubset({'Yes', 'No'}):\n",
    "        binary.append(col)\n",
    "        data[col] = data[col].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313cddb4",
   "metadata": {},
   "source": [
    "<b>Visualizing distributions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff753937",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x = 'churn', y = 'tenure', data = data)\n",
    "plt.title('Differences in tenure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x = 'churn', y = 'monthlycharges', data = data)\n",
    "plt.title('Differences in monthly charges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83681b1",
   "metadata": {},
   "source": [
    "The probability of churn is higher if monthly charges bigger and less if tenure is longer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3047b",
   "metadata": {},
   "source": [
    "<b>Separate categorical and numerical columns</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e049d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the identifier and target variable names as lists\n",
    "custid = ['customerid']\n",
    "target = ['churn']\n",
    "# Separate categorical and numeric column names as lists\n",
    "categorical = data.nunique()[data.nunique()<10].keys().tolist()\n",
    "categorical = [x for x in categorical if x not in binary]\n",
    "binary.remove(target[0])\n",
    "numerical = [col for col in data.columns if col not in custid + target + categorical + binary]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ee2b1",
   "metadata": {},
   "source": [
    "<b>Standardization</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826ce7e",
   "metadata": {},
   "source": [
    "Centers distribution around the mean. Calculates the number of standard deviations away from the mean each point is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1594204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler to numerical columns\n",
    "scaled_numerical = StandardScaler().fit_transform(data[numerical])\n",
    "# Build a dataframe\n",
    "scaled_numerical = pd.DataFrame(data=scaled_numerical, columns=numerical)\n",
    "scaled_numerical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f083196",
   "metadata": {},
   "source": [
    "<b>One hot encoding</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding categorical variables\n",
    "data = pd.get_dummies(data=data, columns=categorical, drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1d008",
   "metadata": {},
   "source": [
    "<b>Bringing it all together</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa90a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-scaled numerical columns\n",
    "data = data.drop(columns=numerical, axis=1)\n",
    "# Merge the non-numerical with the scaled numerical data\n",
    "data = data.merge(right=scaled_numerical,\n",
    "                     how='left',\n",
    "                     left_index=True,\n",
    "                     right_index=True\n",
    "                    )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c51db",
   "metadata": {},
   "source": [
    "<b>Dropping correlated features</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566e47c",
   "metadata": {},
   "source": [
    "Highly correlated features can be droped. They provide no additional information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11add5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = data.corr().abs()\n",
    "\n",
    "# Define a threshold for high correlation\n",
    "threshold = 0.9\n",
    "\n",
    "# Identify highly correlated features\n",
    "to_drop = set()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix.iloc[i, j] > threshold:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            to_drop.add(colname)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated features\n",
    "data_reduced = data.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2d5dd",
   "metadata": {},
   "source": [
    "<b>Churn prediction</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e7770",
   "metadata": {},
   "source": [
    "Model selection: 1. Logistic regression (simple and interpretable bu can't capture complex relationship) 2. Random forests 3. Support vector machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e686cbc",
   "metadata": {},
   "source": [
    "<b>Support Vector Classifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0873525",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in data_reduced.columns if x not in custid + target]\n",
    "X = data_reduced[features]\n",
    "Y = np.ravel(data_reduced[target])\n",
    "train_X, test_X,  train_Y, test_Y = train_test_split(X, Y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=99)\n",
    "# Print shapes of the datasets\n",
    "print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e36fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear', 'poly']  # 'rbf' is used for non-linear, 'linear' for linear, 'poly' for polynomial kernel\n",
    "}\n",
    "# Initialize the SVC classifier\n",
    "svc = SVC(random_state=99)\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "# Fit the GridSearchCV\n",
    "grid_search.fit(train_X, train_Y)\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "# Use the best model to make predictions\n",
    "svc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ca615",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "pred_Y = svc.predict(test_X)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_Y, pred_Y)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "conf_matrix = confusion_matrix(test_Y, pred_Y)\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ac0c9",
   "metadata": {},
   "source": [
    "\n",
    "<b>Logistic Regression Classifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']  # 'liblinear' is suitable for small datasets\n",
    "}\n",
    "# Initialize the logistic regression model\n",
    "logreg = LogisticRegression(random_state=99)\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "# Fit the GridSearchCV\n",
    "grid_search.fit(train_X, train_Y)\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "# Use the best model to make predictions\n",
    "logreg = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label\n",
    "pred_Y = logreg.predict(test_X)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_Y, pred_Y)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3daae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a007df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "conf_matrix = confusion_matrix(test_Y, pred_Y)\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dadc45",
   "metadata": {},
   "source": [
    "<b>Decision Tree Classifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae67646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "# Initialize the Decision Tree classifier\n",
    "dtc = DecisionTreeClassifier(random_state=99)\n",
    "# Initialize GridSearchCV\n",
    "grid_search_dt = GridSearchCV(estimator=dtc, param_grid=param_grid_dt, cv=5, verbose=1, n_jobs=-1)\n",
    "# Fit the GridSearchCV\n",
    "grid_search.fit(train_X, train_Y)\n",
    "# Get the best parameters\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "print(f\"Best parameters found for Decision Tree: {best_params_dt}\")\n",
    "# Use the best model to make predictions\n",
    "dtc = grid_search_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "pred_Y = dtc.predict(test_X)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_Y, pred_Y)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dbf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "conf_matrix = confusion_matrix(test_Y, pred_Y)\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604307c1",
   "metadata": {},
   "source": [
    "<b>Random Forest Classifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "# Initialize the Random Forest classifier\n",
    "rfc = RandomForestClassifier(random_state=99)\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rfc, param_grid=param_grid_rf, cv=5, verbose=1, n_jobs=-1)\n",
    "# Fit the GridSearchCV\n",
    "grid_search_rf.fit(train_X, train_Y)\n",
    "# Get the best parameters\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f\"Best parameters found for Random Forest: {best_params_rf}\")\n",
    "# Use the best model to make predictions\n",
    "rfc = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "pred_Y = rfc.predict(test_X)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_Y, pred_Y)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7b617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "conf_matrix = confusion_matrix(test_Y, pred_Y)\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155580f",
   "metadata": {},
   "source": [
    "<b>ROC curve</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b8b85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict probabilities on the test data\n",
    "y_pred_prob_sv = svc.predict_proba(test_X)[:, 1]\n",
    "y_pred_prob_lr = logreg.predict_proba(test_X)[:, 1]\n",
    "y_pred_prob_dt = dtc.predict_proba(test_X)[:, 1]\n",
    "y_pred_prob_rf = rfc.predict_proba(test_X)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC for Support Vector\n",
    "fpr_sv, tpr_sv, _ = roc_curve(test_Y, y_pred_prob_sv)\n",
    "roc_auc_sv = auc(fpr_sv, tpr_sv)\n",
    "\n",
    "# Compute ROC curve and AUC for Logistic Regression\n",
    "fpr_lr, tpr_lr, _ = roc_curve(test_Y, y_pred_prob_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "# Compute ROC curve and AUC for Decision Tree\n",
    "fpr_dt, tpr_dt, _ = roc_curve(test_Y, y_pred_prob_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# Compute ROC curve and AUC for Random Forest\n",
    "fpr_rf, tpr_rf, _ = roc_curve(test_Y, y_pred_prob_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_sv, tpr_sv, color='olivedrab', lw=2, label=f'Support Vector (AUC = {roc_auc_sv:.2f})')\n",
    "plt.plot(fpr_lr, tpr_lr, color='darkred', lw=2, label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot(fpr_dt, tpr_dt, color='coral', lw=2, label=f'Decision Tree (AUC = {roc_auc_dt:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, color='teal', lw=2, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d29180",
   "metadata": {},
   "source": [
    "Best well-performing model is Logistic Regression in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a464e5",
   "metadata": {},
   "source": [
    "<b>Principal component analysis</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b95c9b",
   "metadata": {},
   "source": [
    "<b>Explained Variance Ratio</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec4294",
   "metadata": {},
   "source": [
    "A common approach is to choose the number of components that explain a sufficient amount of total variance, typically 90% to 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7696d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(data_reduced.iloc[:, 1:])\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='cornflowerblue')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Determine the number of components that explain at least 95% of the variance\n",
    "optimal_components = next(x[0] for x in enumerate(cumulative_explained_variance) if x[1] >= 0.95) + 1\n",
    "print(f'Optimal number of components: {optimal_components}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42bc00",
   "metadata": {},
   "source": [
    "<b>Scree Plot</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8667e8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot explained variance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--', color='cornflowerblue')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad22962",
   "metadata": {},
   "source": [
    "A scree plot shows the explained variance for each principal component. The \"elbow\" point in the plot indicates the optimal number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c85536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA\n",
    "pca = PCA(n_components=18)  # Adjust the number of components to your actual needs\n",
    "pca.fit(data_reduced.iloc[:, 1:])\n",
    "# Extract loadings (components)\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(pca.n_components_)], index=data_reduced.iloc[:, 1:].columns)\n",
    "# Create a heatmap of loadings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(loadings, annot=True, fmt='.1%', linewidths=1, cmap='coolwarm', annot_kws = {'size': 6})\n",
    "plt.title('Correlation Heatmap of components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meaningful names based on loadings\n",
    "def interpret_pca_loadings(loadings, top_n=2):\n",
    "    component_names = []\n",
    "    for col in loadings.columns:\n",
    "        # Get the top_n features for each component\n",
    "        top_features = loadings[col].abs().sort_values(ascending=False).head(top_n).index\n",
    "        component_name = '+'.join(top_features)\n",
    "        component_names.append(component_name)\n",
    "    return component_names\n",
    "\n",
    "# Generate meaningful names\n",
    "component_names = interpret_pca_loadings(loadings)\n",
    "component_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the component names to the principal components DataFrame\n",
    "principal_components = pd.DataFrame(pca.transform(data_reduced.iloc[:, 1:]), columns=component_names)\n",
    "principal_components.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
